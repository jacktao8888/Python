#正则表达式、html.parser、Beautiful Soup、lxml

##模糊化解析：正则表达式

##结构化解析（DOM树-Document Object Model）：html.parser、Beautiful Soup、lxml

###安装beautisoup4：
    WIN7下先添加python的环境变量（cmd下set PATH=%PATH%;D:\software\Python27，好像只能这么添加），
    然后安装pip工具（python setup.py install），最后通过pip工具安装beautifulsoup4(pip install beautifulsoup4)

###应用BeautifulSoup解析网页：
    soup=BeautifulSoup(
                   html_doc,
                   'html.parser',
                   from_encoding='utf-8'
                   )
    ####查找节点：soup.find_all(nodename,attrs,string)
                  soup.find_all('a',href='',string='python')
    ####找到节点：  如<a href='1.html'>Python</a>
                    node.name           //获取查找到的节点的标签名称
                    node['href']        //获得查找到的a节点的href属性
                    node.get_text()     //获取查找到的a节点的链接文字

        例：
            from bs4 import BeautifulSoup

            html_doc = """
            <html><head><title>The Dormouse's story</title></head>
            <body>
            <p class="title"><b>The Dormouse's story</b></p>
            
            <p class="story">Once upon a time there were three little sisters; and their names were
            <a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
            <a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
            <a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
            and they lived at the bottom of a well.</p>
            
            <p class="story">...</p>
            """
            
            soup=BeautifulSoup(
                               html_doc,
                               'html.parser',
                               from_encoding='utf-8'
                               )
            
            links=soup.find_all('a')
            for link in links:
                print link.name,link['href'],link.get_text()
